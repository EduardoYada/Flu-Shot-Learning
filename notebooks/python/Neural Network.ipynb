{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T03:43:05.500027Z",
     "start_time": "2020-11-22T03:43:04.095262Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.preprocessing import FunctionTransformer, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from d2l import torch as d2l\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T03:43:06.230656Z",
     "start_time": "2020-11-22T03:43:06.150758Z"
    }
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"../../data/training_set_features.csv\").drop(\"respondent_id\", axis=1)\n",
    "Y = pd.read_csv(\"../../data/training_set_labels.csv\").drop(\"respondent_id\", axis=1)\n",
    "\n",
    "features = list(X)\n",
    "targets = list(Y)\n",
    "\n",
    "target = targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T03:43:06.476227Z",
     "start_time": "2020-11-22T03:43:06.459269Z"
    }
   },
   "outputs": [],
   "source": [
    "X_df_train, X_df_test, y_df_train, y_df_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "cat_features = [i for i in range(len(features))]\n",
    "nominal_features = list(X_df_train.select_dtypes(object))\n",
    "nominal_features_idx = [features.index(feature) for feature in nominal_features]\n",
    "ordinal_features_idx = [feature_idx for feature_idx in cat_features if feature_idx not in nominal_features_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T03:43:07.079151Z",
     "start_time": "2020-11-22T03:43:07.075190Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_str(x):\n",
    "    return x.astype(str)\n",
    "\n",
    "def to_tensor(x):\n",
    "    return torch.tensor(x.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T03:43:07.374953Z",
     "start_time": "2020-11-22T03:43:07.369966Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train_seasonal = torch.tensor(y_df_train['seasonal_vaccine'].values.astype(np.float32)).long()\n",
    "y_train_h1n1 = torch.tensor(y_df_train['h1n1_vaccine'].values.astype(np.float32)).long()\n",
    "\n",
    "y_test_seasonal = torch.tensor(y_df_test['seasonal_vaccine'].values.astype(np.float32)).long()\n",
    "y_test_h1n1 = torch.tensor(y_df_test['h1n1_vaccine'].values.astype(np.float32)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T03:43:08.896082Z",
     "start_time": "2020-11-22T03:43:07.705577Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    (\n",
    "        'preprocessing',\n",
    "        Pipeline(steps=[\n",
    "            ('fillna', SimpleImputer(strategy='constant', fill_value=\"nan\", copy=False)),\n",
    "            ('to_str', FunctionTransformer(to_str)),\n",
    "            ('encoder', ColumnTransformer(\n",
    "                [('nominal', OneHotEncoder(), nominal_features_idx),\n",
    "                 ('ordinal', OrdinalEncoder(), ordinal_features_idx)], remainder='passthrough')),\n",
    "            ('to_tensor', FunctionTransformer(to_tensor))\n",
    "        ])\n",
    "    )\n",
    "])\n",
    "\n",
    "pipeline.fit(X_df_train)\n",
    "X_train = pipeline.transform(X_df_train)\n",
    "X_test = pipeline.transform(X_df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T03:43:08.992824Z",
     "start_time": "2020-11-22T03:43:08.978862Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):  #@save\n",
    "    \"\"\"Compute the number of correct predictions.\"\"\"\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(d2l.reduce_sum(cmp.type(y.dtype)))\n",
    "\n",
    "\n",
    "def evaluate_accuracy(net, data_iter):  #@save\n",
    "    \"\"\"Compute the accuracy for a model on a dataset.\"\"\"\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval()  # Set the model to evaluation mode\n",
    "    metric = Accumulator(2)  # No. of correct predictions, no. of predictions\n",
    "    for X, y in data_iter:\n",
    "        metric.add(accuracy(net(X), y), d2l.size(y))\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "\n",
    "class Accumulator:  #@save\n",
    "    \"\"\"For accumulating sums over `n` variables.\"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "    \n",
    "def train_epoch_ch3(net, train_iter, loss, updater):  #@save\n",
    "    \"\"\"The training loop defined in Chapter 3.\"\"\"\n",
    "    # Set the model to training mode\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.train()\n",
    "    # Sum of training loss, sum of training accuracy, no. of examples\n",
    "    metric = Accumulator(3)\n",
    "    for X, y in train_iter:\n",
    "        # Compute gradients and update parameters\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y)\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            # Using PyTorch in-built optimizer & loss criterion\n",
    "            updater.zero_grad()\n",
    "            l.backward()\n",
    "            updater.step()\n",
    "            metric.add(float(l) * len(y), accuracy(y_hat, y),\n",
    "                       y.size().numel())\n",
    "        else:\n",
    "            # Using custom built optimizer & loss criterion\n",
    "            l.sum().backward()\n",
    "            updater(X.shape[0])\n",
    "            metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())\n",
    "    # Return training loss and training accuracy\n",
    "    return metric[0] / metric[2], metric[1] / metric[2]\n",
    "\n",
    "\n",
    "class Animator:  #@save\n",
    "    \"\"\"For plotting data in animation.\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(5, 3)):\n",
    "        # Incrementally plot multiple lines\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        d2l.use_svg_display()\n",
    "        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes, ]\n",
    "        # Use a lambda function to capture arguments\n",
    "        self.config_axes = lambda: d2l.set_axes(\n",
    "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def add(self, x, y):\n",
    "        # Add multiple data points into the figure\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)\n",
    "        \n",
    "        \n",
    "def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater):  #@save\n",
    "    \"\"\"Train a model (defined in Chapter 3).\"\"\"\n",
    "    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9],\n",
    "                        legend=['train loss', 'train acc', 'test acc'])\n",
    "    for epoch in range(num_epochs):\n",
    "        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)\n",
    "        test_acc = evaluate_accuracy(net, test_iter)\n",
    "        animator.add(epoch + 1, train_metrics + (test_acc,))\n",
    "    train_loss, train_acc = train_metrics\n",
    "    assert train_loss < 0.5, train_loss\n",
    "    assert train_acc <= 1 and train_acc > 0.7, train_acc\n",
    "    assert test_acc <= 1 and test_acc > 0.7, test_acc\n",
    "    \n",
    "    \n",
    "numpy = lambda x, *args, **kwargs: x.detach().numpy(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T04:16:58.920180Z",
     "start_time": "2020-11-22T04:16:58.913228Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.normal_(m.weight, std=0.01)\n",
    "\n",
    "class NeuralNetwork():\n",
    "    def __init__(self, net, loss, optimizer, lr, num_epochs, batch_size=32):\n",
    "        self.net = net\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer(self.net.parameters(), lr=lr)\n",
    "        self.num_epochs = num_epochs\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def fit(self, X_tensor, y_tensor):\n",
    "        self.net.apply(init_weights)\n",
    "        train_tensor = data.TensorDataset(X_tensor, y_tensor) \n",
    "        train_iter = data.DataLoader(dataset = train_tensor, batch_size = self.batch_size, shuffle = True)\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            for X, y in train_iter:\n",
    "                # Compute gradients and update parameters\n",
    "                y_hat = self.net(X)\n",
    "                l = self.loss(y_hat, y)\n",
    "                self.optimizer.zero_grad()\n",
    "                l.backward()\n",
    "                self.optimizer.step()\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def predict(self, X_tensor):\n",
    "        return numpy(self.net(X_tensor))[:, 1]\n",
    "    \n",
    "    def score(self, X_tensor, y_tensor):\n",
    "        predictions = self.predict(X_tensor)\n",
    "        return roc_auc_score(y_tensor.numpy(), predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H1N1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T04:16:59.484893Z",
     "start_time": "2020-11-22T04:16:59.479878Z"
    }
   },
   "outputs": [],
   "source": [
    "num_features = X_train.shape[1]\n",
    "num_classes = 2\n",
    "num_hidden = 128\n",
    "dropout1, dropout2 = 0., 0.\n",
    "\n",
    "lr = 0.1\n",
    "num_epochs = 16\n",
    "\n",
    "model_params = {\"net\": nn.Sequential(nn.Linear(num_features, num_hidden),\n",
    "                                     nn.ReLU(),\n",
    "                                     # Add a dropout layer after the first fully connected layer\n",
    "                                     nn.Dropout(dropout1),\n",
    "                                     nn.Linear(num_hidden, num_hidden),\n",
    "                                     nn.ReLU(),\n",
    "                                     # Add a dropout layer after the second fully connected layer\n",
    "                                     nn.Dropout(dropout2),\n",
    "                                     nn.Linear(num_hidden, num_classes)),\n",
    "                \"loss\": nn.CrossEntropyLoss(),\n",
    "                \"optimizer\": torch.optim.SGD,\n",
    "                \"lr\": lr,\n",
    "                \"num_epochs\": num_epochs,\n",
    "                \"batch_size\": 32\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T04:17:07.537186Z",
     "start_time": "2020-11-22T04:16:59.815542Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8601649828397444"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model_h1n1 = NeuralNetwork(**model_params)\n",
    "\n",
    "nn_model_h1n1.fit(X_train, y_train_h1n1)\n",
    "nn_model_h1n1.score(X_test, y_test_h1n1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T04:17:07.543170Z",
     "start_time": "2020-11-22T04:17:07.538184Z"
    }
   },
   "outputs": [],
   "source": [
    "num_features = X_train.shape[1]\n",
    "num_classes = 2\n",
    "num_hidden = 128\n",
    "dropout1, dropout2 = 0., 0.\n",
    "\n",
    "lr = 0.1\n",
    "num_epochs = 16\n",
    "\n",
    "model_params = {\"net\": nn.Sequential(nn.Linear(num_features, num_hidden),\n",
    "                                     nn.ReLU(),\n",
    "                                     # Add a dropout layer after the first fully connected layer\n",
    "                                     nn.Dropout(dropout1),\n",
    "                                     nn.Linear(num_hidden, num_hidden),\n",
    "                                     nn.ReLU(),\n",
    "                                     # Add a dropout layer after the second fully connected layer\n",
    "                                     nn.Dropout(dropout2),\n",
    "                                     nn.Linear(num_hidden, num_classes)),\n",
    "                \"loss\": nn.CrossEntropyLoss(),\n",
    "                \"optimizer\": torch.optim.SGD,\n",
    "                \"lr\": lr,\n",
    "                \"num_epochs\": num_epochs,\n",
    "                \"batch_size\": 32\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T04:17:15.268248Z",
     "start_time": "2020-11-22T04:17:07.544168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.858506945206877"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model_seasonal = NeuralNetwork(**model_params)\n",
    "\n",
    "nn_model_seasonal.fit(X_train, y_train_seasonal)\n",
    "nn_model_seasonal.score(X_test, y_test_seasonal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T04:17:15.293181Z",
     "start_time": "2020-11-22T04:17:15.269245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8593359640233107\n"
     ]
    }
   ],
   "source": [
    "test_predictions_seasonal = nn_model_seasonal.predict(X_test)\n",
    "test_predictions_h1n1 = nn_model_h1n1.predict(X_test)\n",
    "\n",
    "combined_predictions = pd.DataFrame({\"h1n1_vaccine\": test_predictions_h1n1,\n",
    "                                     \"seasonal_vaccine\": test_predictions_seasonal})\n",
    "\n",
    "print(roc_auc_score(y_df_test, combined_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T04:17:15.299166Z",
     "start_time": "2020-11-22T04:17:15.294178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "GeForce RTX 2060\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T03:19:04.031832Z",
     "start_time": "2020-11-14T03:19:01.031381Z"
    }
   },
   "outputs": [],
   "source": [
    "X_holdout = pd.read_csv(\"../../data/test_set_features.csv\")\n",
    "X_holdout_processed = pipeline.transform(X_holdout.drop(\"respondent_id\", axis=1))\n",
    "\n",
    "holdout_predictions = cce.predict_proba(X_holdout_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T03:19:08.110824Z",
     "start_time": "2020-11-14T03:19:08.009975Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(holdout_predictions, columns=['h1n1_vaccine', 'seasonal_vaccine'])\n",
    "submission_df['respondent_id'] = X_holdout['respondent_id']\n",
    "submission_df[['respondent_id', 'h1n1_vaccine', 'seasonal_vaccine']].to_csv(\"../submissions/classifier_chain_gb.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "d2l"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "notify_time": "30",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
